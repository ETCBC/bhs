{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"images/dans-small.png\"/>\n",
    "<img align=\"right\" src=\"images/tf-small.png\"/>\n",
    "<img align=\"right\" src=\"images/etcbc.png\"/>\n",
    "\n",
    "\n",
    "#  Statistics\n",
    "\n",
    "This notebook adds statistical features to a\n",
    "[BHSA](https://github.com/ETCBC/bhsa) dataset in\n",
    "[text-Fabric](https://github.com/Dans-labs/text-fabric)\n",
    "format.\n",
    "\n",
    "## Discussion\n",
    "\n",
    "We add the features\n",
    "`freq_occ freq_lex rank_occ rank_lex`.\n",
    "\n",
    "We assume that the dataset has these features present:\n",
    "\n",
    "* LANG_FEATURE (typically `languageISO`) for determining if the word is Hebrew or Aramaic\n",
    "* OCC_FEATURE (typically `g_cons`) to get the word string in consonantal transcription\n",
    "* LEX_FEATURE (typically `lex`) to get the lexical identifier in consonantal transcription\n",
    "\n",
    "This program works for all datasets and versions that have these features with the\n",
    "intended meanings. The exact names of these features can be passed as parameters.\n",
    "Note that the old version `3` uses very different names for many features.\n",
    "\n",
    "#### Languages\n",
    "We will not identify lexemes and word occurrences across language.\n",
    "So if two occurrences or lexemes exhibit the same string, but they are categorized as belonging\n",
    "to different languages, they will not be identified.\n",
    "\n",
    "#### Occurrences\n",
    "We group occurrences by their consonantal transcriptions.\n",
    "So if two occurrences differ only in pointing, we count them as two occurrences of the same value.\n",
    "\n",
    "#### Lexemes\n",
    "Lexemes are identified by the `lex` feature within a biblical language.\n",
    "We will not identify lexemes across language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import collections\n",
    "import utils\n",
    "from tf.fabric import Fabric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "See [operation](https://github.com/ETCBC/pipeline/blob/master/README.md#operation)\n",
    "for how to run this script in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if \"SCRIPT\" not in locals():\n",
    "    SCRIPT = False\n",
    "    FORCE = True\n",
    "    CORE_NAME = \"bhsa\"\n",
    "    VERSION = \"2021\"\n",
    "    LANG_FEATURE = \"languageISO\"\n",
    "    OCC_FEATURE = \"g_cons\"\n",
    "    LEX_FEATURE = \"lex\"\n",
    "\n",
    "\n",
    "def stop(good=False):\n",
    "    if SCRIPT:\n",
    "        sys.exit(0 if good else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the context: source file and target directories\n",
    "\n",
    "The conversion is executed in an environment of directories, so that sources, temp files and\n",
    "results are in convenient places and do not have to be shifted around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repoBase = os.path.expanduser(\"~/github/etcbc\")\n",
    "thisRepo = \"{}/{}\".format(repoBase, CORE_NAME)\n",
    "\n",
    "thisTemp = \"{}/_temp/{}\".format(thisRepo, VERSION)\n",
    "thisTempTf = \"{}/tf\".format(thisTemp)\n",
    "\n",
    "thisTf = \"{}/tf/{}\".format(thisRepo, VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "newFeaturesStr = \"\"\"\n",
    "    freq_occ\n",
    "    freq_lex\n",
    "    rank_occ\n",
    "    rank_lex\n",
    "\"\"\"\n",
    "newFeatures = newFeaturesStr.strip().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "Check whether this conversion is needed in the first place.\n",
    "Only when run as a script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if SCRIPT:\n",
    "    (good, work) = utils.mustRun(\n",
    "        None, \"{}/.tf/{}.tfx\".format(thisTf, newFeatures[0]), force=FORCE\n",
    "    )\n",
    "    if not good:\n",
    "        stop(good=False)\n",
    "    if not work:\n",
    "        stop(good=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect\n",
    "\n",
    "We collect the statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".       0.00s Loading relevant features                                                      .\n",
      "..............................................................................................\n",
      "This is Text-Fabric 9.0.2\n",
      "Api reference : https://annotation.github.io/text-fabric/tf/cheatsheet.html\n",
      "\n",
      "114 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.00s Dataset without structure sections in otext:no structure functions in the T-API\n",
      "  4.03s All features loaded/computed - for details use TF.isLoaded()\n"
     ]
    }
   ],
   "source": [
    "utils.caption(4, \"Loading relevant features\")\n",
    "\n",
    "TF = Fabric(locations=thisTf, modules=[\"\"])\n",
    "api = TF.load(\"{} {} {}\".format(LANG_FEATURE, LEX_FEATURE, OCC_FEATURE))\n",
    "api.makeAvailableIn(globals())\n",
    "\n",
    "hasLex = \"lex\" in set(F.otype.all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|       5.66s Counting occurrences\n"
     ]
    }
   ],
   "source": [
    "utils.caption(0, \"Counting occurrences\")\n",
    "wstats = {\n",
    "    \"freqs\": {\n",
    "        \"lex\": collections.defaultdict(lambda: collections.Counter()),\n",
    "        \"occ\": collections.defaultdict(lambda: collections.Counter()),\n",
    "    },\n",
    "    \"ranks\": {\n",
    "        \"lex\": collections.defaultdict(lambda: {}),\n",
    "        \"occ\": collections.defaultdict(lambda: {}),\n",
    "    },\n",
    "}\n",
    "langs = set()\n",
    "\n",
    "for w in F.otype.s(\"word\"):\n",
    "    occ = Fs(OCC_FEATURE).v(w)\n",
    "    lex = Fs(LEX_FEATURE).v(w)\n",
    "    lan = Fs(LANG_FEATURE).v(w)\n",
    "    wstats[\"freqs\"][\"lex\"][lan][lex] += 1\n",
    "    wstats[\"freqs\"][\"occ\"][lan][occ] += 1\n",
    "    langs.add(lan)\n",
    "for lan in langs:\n",
    "    for tp in [\"lex\", \"occ\"]:\n",
    "        rank = -1\n",
    "        prev_n = -1\n",
    "        amount = 1\n",
    "        for (x, n) in sorted(\n",
    "            wstats[\"freqs\"][tp][lan].items(), key=lambda y: (-y[1], y[0])\n",
    "        ):\n",
    "            if n == prev_n:\n",
    "                amount += 1\n",
    "            else:\n",
    "                rank += amount\n",
    "                amount = 1\n",
    "            prev_n = n\n",
    "            wstats[\"ranks\"][tp][lan][x] = rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|         20s Making statistical features\n"
     ]
    }
   ],
   "source": [
    "utils.caption(0, \"Making statistical features\")\n",
    "metaData = {\n",
    "    \"\": dict(\n",
    "        dataset=\"BHSA\",\n",
    "        version=VERSION,\n",
    "        datasetName=\"Biblia Hebraica Stuttgartensia Amstelodamensis\",\n",
    "        author=\"Eep Talstra Centre for Bible and Computer\",\n",
    "        provenance=\"computed addition to core set of features\",\n",
    "        encoders=\"Dirk Roorda (TF)\",\n",
    "        website=\"https://shebanq.ancient-data.org\",\n",
    "        email=\"shebanq@ancient-data.org\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "nodeFeatures = {}\n",
    "edgeFeatures = {}\n",
    "\n",
    "for ft in newFeatures:\n",
    "    nodeFeatures[ft] = {}\n",
    "    metaData.setdefault(ft, {})[\"valueType\"] = \"int\"\n",
    "\n",
    "for w in F.otype.s(\"word\"):\n",
    "    lan = Fs(LANG_FEATURE).v(w)\n",
    "    occ = Fs(OCC_FEATURE).v(w)\n",
    "    lex = Fs(LEX_FEATURE).v(w)\n",
    "    nodeFeatures[\"freq_occ\"][w] = str(wstats[\"freqs\"][\"occ\"][lan][occ])\n",
    "    nodeFeatures[\"rank_occ\"][w] = str(wstats[\"ranks\"][\"occ\"][lan][occ])\n",
    "    nodeFeatures[\"freq_lex\"][w] = str(wstats[\"freqs\"][\"lex\"][lan][lex])\n",
    "    nodeFeatures[\"rank_lex\"][w] = str(wstats[\"ranks\"][\"lex\"][lan][lex])\n",
    "\n",
    "if hasLex:\n",
    "    for lx in F.otype.s(\"lex\"):\n",
    "        firstOcc = L.d(lx, otype=\"word\")[0]\n",
    "        nodeFeatures[\"freq_lex\"][lx] = nodeFeatures[\"freq_lex\"][firstOcc]\n",
    "        nodeFeatures[\"rank_lex\"][lx] = nodeFeatures[\"rank_lex\"][firstOcc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".         22s Write statistical features as TF                                               .\n",
      "..............................................................................................\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.caption(4, \"Write statistical features as TF\")\n",
    "TF = Fabric(locations=thisTempTf, silent=True)\n",
    "TF.save(nodeFeatures=nodeFeatures, edgeFeatures=edgeFeatures, metaData=metaData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffs\n",
    "\n",
    "Check differences with previous versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".         26s Check differences with previous version                                        .\n",
      "..............................................................................................\n",
      "|         26s \tno features to add\n",
      "|         26s \tno features to delete\n",
      "|         26s \t4 features in common\n",
      "|         26s freq_lex                  ... no changes\n",
      "|         27s freq_occ                  ... no changes\n",
      "|         27s rank_lex                  ... no changes\n",
      "|         27s rank_occ                  ... no changes\n",
      "|         27s Done\n"
     ]
    }
   ],
   "source": [
    "utils.checkDiffs(thisTempTf, thisTf, only=set(newFeatures))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deliver\n",
    "\n",
    "Copy the new TF features from the temporary location where they have been created to their final destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".         29s Deliver features to /Users/dirk/github/etcbc/bhsa/tf/2021                      .\n",
      "..............................................................................................\n",
      "|         29s \tfreq_occ\n",
      "|         29s \tfreq_lex\n",
      "|         29s \trank_occ\n",
      "|         29s \trank_lex\n"
     ]
    }
   ],
   "source": [
    "utils.deliverFeatures(thisTempTf, thisTf, newFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".     11m 04s Load and compile the new TF features                                           .\n",
      "..............................................................................................\n",
      "This is Text-Fabric 9.0.2\n",
      "Api reference : https://annotation.github.io/text-fabric/tf/cheatsheet.html\n",
      "\n",
      "114 features found and 0 ignored\n",
      "lex \n",
      "    freq_occ\n",
      "    freq_lex\n",
      "    rank_occ\n",
      "    rank_lex\n",
      "\n",
      "  0.00s loading features ...\n",
      "   |     0.00s Dataset without structure sections in otext:no structure functions in the T-API\n",
      "   |     0.62s T freq_lex             from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.59s T freq_occ             from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.60s T rank_lex             from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.61s T rank_occ             from ~/github/etcbc/bhsa/tf/2021\n",
      "  6.22s All features loaded/computed - for details use TF.isLoaded()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Computed',\n",
       "  'computed-data',\n",
       "  ('C Computed', 'Call AllComputeds', 'Cs ComputedString')),\n",
       " ('Features', 'edge-features', ('E Edge', 'Eall AllEdges', 'Es EdgeString')),\n",
       " ('Fabric', 'loading', ('TF',)),\n",
       " ('Locality', 'locality', ('L Locality',)),\n",
       " ('Nodes', 'navigating-nodes', ('N Nodes',)),\n",
       " ('Features',\n",
       "  'node-features',\n",
       "  ('F Feature', 'Fall AllFeatures', 'Fs FeatureString')),\n",
       " ('Search', 'search', ('S Search',)),\n",
       " ('Text', 'text', ('T Text',))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.caption(4, \"Load and compile the new TF features\")\n",
    "\n",
    "TF = Fabric(locations=thisTf, modules=[\"\"])\n",
    "api = TF.load(\"{} {}\".format(LEX_FEATURE, newFeaturesStr))\n",
    "api.makeAvailableIn(globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".         42s Basic test                                                                     .\n",
      "..............................................................................................\n",
      "|         42s Top 10 freqent lexemes (computed on otype=word)\n",
      "|         42s W           50272x\n",
      "|         42s H           30386x\n",
      "|         42s L           20069x\n",
      "|         42s B           15542x\n",
      "|         42s >T          10987x\n",
      "|         42s MN           7562x\n",
      "|         42s JHWH/        6828x\n",
      "|         42s <L           5766x\n",
      "|         42s >L           5517x\n",
      "|         42s >CR          5500x\n",
      "..............................................................................................\n",
      ".         42s Top 10 freqent lexemes (computed on otype=lex)                                 .\n",
      "..............................................................................................\n",
      "|         42s W           50272x\n",
      "|         42s H           30386x\n",
      "|         42s L           20069x\n",
      "|         42s B           15542x\n",
      "|         42s >T          10987x\n",
      "|         42s MN           7562x\n",
      "|         42s JHWH/        6828x\n",
      "|         42s <L           5766x\n",
      "|         42s >L           5517x\n",
      "|         42s >CR          5500x\n",
      "|         42s \tINFO: Same lexeme frequencies computed by lex vs by word\n",
      "|         42s Done\n"
     ]
    }
   ],
   "source": [
    "utils.caption(4, \"Basic test\")\n",
    "\n",
    "mostFrequent = set()\n",
    "\n",
    "topX = 10\n",
    "\n",
    "lexIndex = {}\n",
    "\n",
    "utils.caption(0, \"Top {} freqent lexemes (computed on otype=word)\".format(topX))\n",
    "for w in sorted(F.otype.s(\"word\"), key=lambda w: -F.freq_lex.v(w)):\n",
    "    lex = Fs(LEX_FEATURE).v(w)\n",
    "    mostFrequent.add(lex)\n",
    "    lexIndex[lex] = w\n",
    "    if len(mostFrequent) == topX:\n",
    "        break\n",
    "\n",
    "mostFrequentWord = sorted((-F.freq_lex.v(lexIndex[lex]), lex) for lex in mostFrequent)\n",
    "for (freq, lex) in mostFrequentWord:\n",
    "    utils.caption(0, \"{:<10} {:>6}x\".format(lex, -freq))\n",
    "\n",
    "if hasLex:\n",
    "    utils.caption(4, \"Top {} freqent lexemes (computed on otype=lex)\".format(topX))\n",
    "    mostFrequentLex = sorted(\n",
    "        (-F.freq_lex.v(lx), F.lex.v(lx)) for lx in F.otype.s(\"lex\")\n",
    "    )[0:10]\n",
    "    for (freq, lex) in mostFrequentLex:\n",
    "        utils.caption(0, \"{:<10} {:>6}x\".format(lex, -freq))\n",
    "\n",
    "    if mostFrequentWord != mostFrequentLex:\n",
    "        utils.caption(\n",
    "            0, \"\\tWARNING: Mismatch in lexeme frequencies computed by lex vs by word\"\n",
    "        )\n",
    "    else:\n",
    "        utils.caption(0, \"\\tINFO: Same lexeme frequencies computed by lex vs by word\")\n",
    "utils.caption(0, \"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if SCRIPT:\n",
    "    stop(good=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
