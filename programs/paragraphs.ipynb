{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"images/dans-small.png\"/>\n",
    "<img align=\"right\" src=\"images/tf-small.png\"/>\n",
    "<img align=\"right\" src=\"images/etcbc.png\"/>\n",
    "\n",
    "\n",
    "# Paragraphs\n",
    "\n",
    "This notebook can read ETCBC `.px` files with information\n",
    "about *paragraphs* in it.\n",
    "We distill a bunch of extra features at the `clause_atom` level, namely:\n",
    "* `pargr`\n",
    "* `instruction`\n",
    "\n",
    "**NB** This conversion will not work for versions `4` and `4b`.\n",
    "\n",
    "## Discussion\n",
    "Somebody should tell in more detail what they are, and document it in the feature documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "from tf.fabric import Fabric\n",
    "import utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "See [operation](https://github.com/ETCBC/pipeline/blob/master/README.md#operation)\n",
    "for how to run this script in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if \"SCRIPT\" not in locals():\n",
    "    SCRIPT = False\n",
    "    FORCE = True\n",
    "    CORE_NAME = \"bhsa\"\n",
    "    VERSION = \"2021\"\n",
    "\n",
    "\n",
    "def stop(good=False):\n",
    "    if SCRIPT:\n",
    "        sys.exit(0 if good else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the context: source file and target directories\n",
    "\n",
    "The conversion is executed in an environment of directories, so that sources, temp files and\n",
    "results are in convenient places and do not have to be shifted around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repoBase = os.path.expanduser(\"~/github/etcbc\")\n",
    "thisRepo = \"{}/{}\".format(repoBase, CORE_NAME)\n",
    "\n",
    "thisSource = \"{}/source/{}\".format(thisRepo, VERSION)\n",
    "\n",
    "thisTemp = \"{}/_temp/{}\".format(thisRepo, VERSION)\n",
    "thisTempSource = \"{}/source\".format(thisTemp)\n",
    "thisTempTf = \"{}/tf\".format(thisTemp)\n",
    "\n",
    "thisTf = \"{}/tf/{}\".format(thisRepo, VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testFeature = \"pargr\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "Check whether this conversion is needed in the first place.\n",
    "Only when run as a script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if SCRIPT:\n",
    "    (good, work) = utils.mustRun(\n",
    "        None, \"{}/.tf/{}.tfx\".format(thisTf, testFeature), force=FORCE\n",
    "    )\n",
    "    if not good:\n",
    "        stop(good=False)\n",
    "    if not work:\n",
    "        stop(good=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Settings\n",
    "\n",
    "* a piece of metadata that will go into these features; the time will be added automatically\n",
    "* new text formats for the `otext` feature of TF, based on lexical features.\n",
    "  We select the version specific otext material,\n",
    "  falling back on a default if nothing appropriate has been specified in oText.\n",
    "\n",
    "We do not do this for the older versions `4` and `4b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "provenanceMetadata = dict(\n",
    "    dataset=\"BHSA\",\n",
    "    datasetName=\"Biblia Hebraica Stuttgartensia Amstelodamensis\",\n",
    "    version=VERSION,\n",
    "    author=\"Eep Talstra Centre for Bible and Computer\",\n",
    "    encoders=\"Constantijn Sikkel (QDF), and Dirk Roorda (TF)\",\n",
    "    website=\"https://shebanq.ancient-data.org\",\n",
    "    email=\"shebanq@ancient-data.org\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".       0.00s Load the existing TF dataset                                                   .\n",
      "..............................................................................................\n",
      "This is Text-Fabric 8.5.13\n",
      "Api reference : https://annotation.github.io/text-fabric/tf/cheatsheet.html\n",
      "\n",
      "80 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.00s Dataset without structure sections in otext:no structure functions in the T-API\n",
      "  3.57s All features loaded/computed - for details use loadLog()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Computed',\n",
       "  'computed-data',\n",
       "  ('C Computed', 'Call AllComputeds', 'Cs ComputedString')),\n",
       " ('Features', 'edge-features', ('E Edge', 'Eall AllEdges', 'Es EdgeString')),\n",
       " ('Fabric', 'loading', ('TF',)),\n",
       " ('Locality', 'locality', ('L Locality',)),\n",
       " ('Nodes', 'navigating-nodes', ('N Nodes',)),\n",
       " ('Features',\n",
       "  'node-features',\n",
       "  ('F Feature', 'Fall AllFeatures', 'Fs FeatureString')),\n",
       " ('Search', 'search', ('S Search',)),\n",
       " ('Text', 'text', ('T Text',))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.caption(4, \"Load the existing TF dataset\")\n",
    "TF = Fabric(locations=thisTf, modules=[\"\"])\n",
    "api = TF.load(\"label number\")\n",
    "api.makeAvailableIn(globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clause atom identifiers in .px\n",
    "We must map the way the clause_atoms are identified in the `.px` files\n",
    "to nodes in TF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|       9.11s \tLabeling clause_atoms\n",
      "|         10s \tOK: clause atoms succesfully labeled\n",
      "|         10s \t90704 clause atoms\n"
     ]
    }
   ],
   "source": [
    "utils.caption(0, \"\\tLabeling clause_atoms\")\n",
    "\n",
    "labelNumberFromNode = {}\n",
    "nodeFromLabelNumber = {}\n",
    "for n in N.walk():\n",
    "    otype = F.otype.v(n)\n",
    "    if otype == \"book\":\n",
    "        curSubtract = 0\n",
    "        curChapterSeq = 0\n",
    "    elif otype == \"chapter\":\n",
    "        curSubtract += curChapterSeq\n",
    "        curChapterSeq = 0\n",
    "    elif otype == \"verse\":\n",
    "        curLabel = F.label.v(n)\n",
    "    elif otype == \"clause_atom\":\n",
    "        curChapterSeq += 1\n",
    "        nm = int(F.number.v(n)) - curSubtract\n",
    "        nodeFromLabelNumber[(curLabel, nm)] = n\n",
    "        labelNumberFromNode[n] = (curLabel, nm)\n",
    "\n",
    "nLabs = len(nodeFromLabelNumber)\n",
    "nNodes = len(labelNumberFromNode)\n",
    "\n",
    "if nLabs == nNodes:\n",
    "    utils.caption(0, \"\\tOK: clause atoms succesfully labeled\")\n",
    "    utils.caption(0, \"\\t{} clause atoms\".format(nNodes))\n",
    "else:\n",
    "    utils.caption(0, \"\\tWARNING: clause atoms not uniquely labeled\")\n",
    "    utils.caption(0, \"\\t{} labels =/= {} nodes\".format(nLabs, nNodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the PX files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".         15s Parsing paragraph data in PX                                                   .\n",
      "..............................................................................................\n",
      "|         15s bunzipping /Users/dirk/github/etcbc/bhsa/source/2021/paragraphs.txt.bz2 ...\n",
      "|         15s \tNOTE: Using existing unzipped file which is newer than bzipped one\n",
      "|         16s \tRead 90704 paragraph annotations\n",
      "|         16s \tOK: All label/line entries found in index\n"
     ]
    }
   ],
   "source": [
    "utils.caption(4, \"Parsing paragraph data in PX\")\n",
    "\n",
    "pxFile = \"{}/paragraphs.txt\".format(thisTempSource)\n",
    "pxzFile = \"{}/paragraphs.txt.bz2\".format(thisSource)\n",
    "utils.caption(0, \"bunzipping {} ...\".format(pxzFile))\n",
    "utils.bunzip(pxzFile, pxFile)\n",
    "pxHandle = open(pxFile)\n",
    "\n",
    "data = []\n",
    "notFound = set()\n",
    "\n",
    "ln = 0\n",
    "can = 0\n",
    "featurescan = re.compile(r\"0 0 (..) [0-9]+ LineNr\\s*([0-9]+).*?Pargr:\\s*([0-9.]+)\")\n",
    "curLabel = None\n",
    "\n",
    "for line in pxHandle:\n",
    "    ln += 1\n",
    "    if line.strip()[0] != \"*\":\n",
    "        curLabel = line[0:10]\n",
    "        continue\n",
    "    can += 1\n",
    "    features = featurescan.findall(line)\n",
    "    if len(features) == 0:\n",
    "        utils.caption(\n",
    "            0, \"\\tWarning: line {}: no instruction, LineNr, Pargr found\".format(ln)\n",
    "        )\n",
    "    elif len(features) > 1:\n",
    "        utils.caption(\n",
    "            0,\n",
    "            \"\\tWarning: line {}: multiple instruction, LineNr, Pargr found\".format(ln),\n",
    "        )\n",
    "    else:\n",
    "        feature = features[0]\n",
    "        theIns = feature[0]\n",
    "        theN = feature[1]\n",
    "        thePara = feature[2]\n",
    "        labNum = (curLabel, int(theN))\n",
    "        if labNum not in nodeFromLabelNumber:\n",
    "            notFound.add(labNum)\n",
    "            continue\n",
    "        data.append((nodeFromLabelNumber[labNum], theIns, theN, thePara))\n",
    "pxHandle.close()\n",
    "utils.caption(0, \"\\tRead {} paragraph annotations\".format(len(data)))\n",
    "\n",
    "if notFound:\n",
    "    utils.caption(\n",
    "        0,\n",
    "        \"\\tWARNING: Could not find {} label/line entries in index: {}\".format(\n",
    "            len(notFound),\n",
    "            sorted({lab for lab in notFound}),\n",
    "        ),\n",
    "    )\n",
    "else:\n",
    "    utils.caption(0, \"\\tOK: All label/line entries found in index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576539, '.N', '1', '1')\n",
      "(576540, '..', '2', '1')\n",
      "(576541, '..', '3', '1')\n",
      "(576542, '..', '4', '1')\n",
      "(576543, '.q', '5', '1.1')\n",
      "(576544, '..', '6', '1.1')\n",
      "(576545, '..', '7', '1.1')\n",
      "(576546, '..', '8', '1.1')\n",
      "(576547, '..', '9', '1.1')\n",
      "(576548, '.q', '10', '1.1.1')\n"
     ]
    }
   ],
   "source": [
    "if not SCRIPT:\n",
    "    print(\"\\n\".join(repr(d) for d in data[0:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare TF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|         21s Prepare TF paragraph features\n"
     ]
    }
   ],
   "source": [
    "utils.caption(0, \"Prepare TF paragraph features\")\n",
    "\n",
    "metaData = {\n",
    "    \"\": provenanceMetadata,\n",
    "}\n",
    "nodeFeatures = {}\n",
    "\n",
    "newFeatures = \"\"\"\n",
    "    pargr\n",
    "    instruction\n",
    "\"\"\".strip().split()\n",
    "\n",
    "nodeFeatures = dict(\n",
    "    instruction=dict(((x[0], x[1]) for x in data)),\n",
    "    pargr=dict(((x[0], x[3]) for x in data)),\n",
    ")\n",
    "\n",
    "for f in nodeFeatures:\n",
    "    metaData[f] = {}\n",
    "    metaData[f][\"valueType\"] = \"str\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "changedFeatures = set(nodeFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write new features\n",
    "Transform the collected information in feature-like data-structures, and write it all\n",
    "out to `.tf` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".         27s write new/changed features to TF ...                                           .\n",
      "..............................................................................................\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.caption(4, \"write new/changed features to TF ...\")\n",
    "TF = Fabric(locations=thisTempTf, silent=True)\n",
    "TF.save(nodeFeatures=nodeFeatures, edgeFeatures={}, metaData=metaData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffs\n",
    "\n",
    "Check differences with previous versions.\n",
    "\n",
    "The new dataset has been created in a temporary directory,\n",
    "and has not yet been copied to its destination.\n",
    "\n",
    "Here is your opportunity to compare the newly created features with the older features.\n",
    "You expect some differences in some features.\n",
    "\n",
    "We check the differences between the previous version of the features and what has been generated.\n",
    "We list features that will be added and deleted and changed.\n",
    "For each changed feature we show the first line where the new feature differs from the old one.\n",
    "We ignore changes in the metadata, because the timestamp in the metadata will always change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".         28s Check differences with previous version                                        .\n",
      "..............................................................................................\n",
      "|         28s \t2 features to add\n",
      "|         28s \t\tinstruction\n",
      "|         28s \t\tpargr\n",
      "|         28s \tno features to delete\n",
      "|         28s \t0 features in common\n",
      "|         28s Done\n"
     ]
    }
   ],
   "source": [
    "utils.checkDiffs(thisTempTf, thisTf, only=changedFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deliver\n",
    "\n",
    "Copy the new TF dataset from the temporary location where it has been created to its final destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".         33s Deliver features to /Users/dirk/github/etcbc/bhsa/tf/2021                      .\n",
      "..............................................................................................\n",
      "|         33s \tpargr\n",
      "|         33s \tinstruction\n"
     ]
    }
   ],
   "source": [
    "utils.deliverFeatures(thisTempTf, thisTf, changedFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile TF\n",
    "\n",
    "We load the new features, use the new format, check some values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".         34s Load and compile the new TF features                                           .\n",
      "..............................................................................................\n",
      "This is Text-Fabric 8.5.13\n",
      "Api reference : https://annotation.github.io/text-fabric/tf/cheatsheet.html\n",
      "\n",
      "82 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.00s Dataset without structure sections in otext:no structure functions in the T-API\n",
      "   |     0.19s T pargr                from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.20s T instruction          from ~/github/etcbc/bhsa/tf/2021\n",
      "  3.99s All features loaded/computed - for details use loadLog()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Computed',\n",
       "  'computed-data',\n",
       "  ('C Computed', 'Call AllComputeds', 'Cs ComputedString')),\n",
       " ('Features', 'edge-features', ('E Edge', 'Eall AllEdges', 'Es EdgeString')),\n",
       " ('Fabric', 'loading', ('TF',)),\n",
       " ('Locality', 'locality', ('L Locality',)),\n",
       " ('Nodes', 'navigating-nodes', ('N Nodes',)),\n",
       " ('Features',\n",
       "  'node-features',\n",
       "  ('F Feature', 'Fall AllFeatures', 'Fs FeatureString')),\n",
       " ('Search', 'search', ('S Search',)),\n",
       " ('Text', 'text', ('T Text',))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.caption(4, \"Load and compile the new TF features\")\n",
    "\n",
    "TF = Fabric(locations=thisTf, modules=[\"\"])\n",
    "api = TF.load(\" \".join(changedFeatures))\n",
    "api.makeAvailableIn(globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".         47s Test: paragraphs of the first verses                                           .\n",
      "..............................................................................................\n",
      "0 1414363 ('Genesis', 1, 1)\n",
      "\tGenesis 1:1\n",
      "\t\t.N             1 בְּרֵאשִׁ֖ית בָּרָ֣א אֱלֹהִ֑ים אֵ֥ת הַשָּׁמַ֖יִם וְאֵ֥ת הָאָֽרֶץ׃ \n",
      "1 1414364 ('Genesis', 1, 2)\n",
      "\tGenesis 1:2\n",
      "\t\t..             1 וְהָאָ֗רֶץ הָיְתָ֥ה תֹ֨הוּ֙ וָבֹ֔הוּ \n",
      "\t\t..             1 וְחֹ֖שֶׁךְ עַל־פְּנֵ֣י תְהֹ֑ום \n",
      "\t\t..             1 וְר֣וּחַ אֱלֹהִ֔ים מְרַחֶ֖פֶת עַל־פְּנֵ֥י הַמָּֽיִם׃ \n",
      "2 1414365 ('Genesis', 1, 3)\n",
      "\tGenesis 1:3\n",
      "\t\t.#           1.1 וַיֹּ֥אמֶר אֱלֹהִ֖ים \n",
      "\t\t.q         1.1.1 יְהִ֣י אֹ֑ור \n",
      "\t\t.#         1.1.2 וַֽיְהִי־אֹֽור׃ \n",
      "3 1414366 ('Genesis', 1, 4)\n",
      "\tGenesis 1:4\n",
      "\t\t.#         1.1.3 וַיַּ֧רְא אֱלֹהִ֛ים אֶת־הָאֹ֖ור \n",
      "\t\t..         1.1.3 כִּי־טֹ֑וב \n",
      "\t\t.#         1.1.4 וַיַּבְדֵּ֣ל אֱלֹהִ֔ים בֵּ֥ין הָאֹ֖ור וּבֵ֥ין הַחֹֽשֶׁךְ׃ \n",
      "4 1414367 ('Genesis', 1, 5)\n",
      "\tGenesis 1:5\n",
      "\t\t.#         1.1.5 וַיִּקְרָ֨א אֱלֹהִ֤ים׀ לָאֹור֙ יֹ֔ום \n",
      "\t\t..         1.1.5 וְלַחֹ֖שֶׁךְ קָ֣רָא לָ֑יְלָה \n",
      "\t\t.#       1.1.5.1 וַֽיְהִי־עֶ֥רֶב \n",
      "\t\t.#       1.1.5.2 וַֽיְהִי־בֹ֖קֶר \n",
      "\t\t..       1.1.5.2 יֹ֥ום אֶחָֽד׃ פ \n",
      "5 1414368 ('Genesis', 1, 6)\n",
      "\tGenesis 1:6\n",
      "\t\t.#           1.2 וַיֹּ֣אמֶר אֱלֹהִ֔ים \n",
      "\t\t.q         1.2.1 יְהִ֥י רָקִ֖יעַ בְּתֹ֣וךְ הַמָּ֑יִם \n",
      "\t\t..         1.2.1 וִיהִ֣י מַבְדִּ֔יל בֵּ֥ין מַ֖יִם לָמָֽיִם׃ \n",
      "6 1414369 ('Genesis', 1, 7)\n",
      "\tGenesis 1:7\n",
      "\t\t.#         1.2.2 וַיַּ֣עַשׂ אֱלֹהִים֮ אֶת־הָרָקִיעַ֒ \n",
      "\t\t..         1.2.2 וַיַּבְדֵּ֗ל בֵּ֤ין הַמַּ֨יִם֙ \n",
      "\t\t.e         1.2.2 אֲשֶׁר֙ מִתַּ֣חַת לָרָקִ֔יעַ \n",
      "\t\td.         1.2.2 וּבֵ֣ין הַמַּ֔יִם \n",
      "\t\t..         1.2.2 אֲשֶׁ֖ר מֵעַ֣ל לָרָקִ֑יעַ \n",
      "\t\t..         1.2.2 וַֽיְהִי־כֵֽן׃ \n",
      "7 1414370 ('Genesis', 1, 8)\n",
      "\tGenesis 1:8\n",
      "\t\t.#       1.2.2.1 וַיִּקְרָ֧א אֱלֹהִ֛ים לָֽרָקִ֖יעַ שָׁמָ֑יִם \n",
      "\t\t.#     1.2.2.1.1 וַֽיְהִי־עֶ֥רֶב \n",
      "\t\t.#     1.2.2.1.2 וַֽיְהִי־בֹ֖קֶר \n",
      "\t\t..     1.2.2.1.2 יֹ֥ום שֵׁנִֽי׃ פ \n",
      "8 1414371 ('Genesis', 1, 9)\n",
      "\tGenesis 1:9\n",
      "\t\t.#           1.3 וַיֹּ֣אמֶר אֱלֹהִ֗ים \n",
      "\t\t.q         1.3.1 יִקָּו֨וּ הַמַּ֜יִם מִתַּ֤חַת הַשָּׁמַ֨יִם֙ אֶל־מָקֹ֣ום אֶחָ֔ד \n",
      "\t\t..         1.3.1 וְתֵרָאֶ֖ה הַיַּבָּשָׁ֑ה \n",
      "\t\t..           1.3 וַֽיְהִי־כֵֽן׃ \n",
      "9 1414372 ('Genesis', 1, 10)\n",
      "\tGenesis 1:10\n",
      "\t\t.#         1.3.2 וַיִּקְרָ֨א אֱלֹהִ֤ים׀ לַיַּבָּשָׁה֙ אֶ֔רֶץ \n",
      "\t\t..         1.3.2 וּלְמִקְוֵ֥ה הַמַּ֖יִם קָרָ֣א יַמִּ֑ים \n",
      "\t\t.#         1.3.3 וַיַּ֥רְא אֱלֹהִ֖ים \n",
      "\t\t..         1.3.3 כִּי־טֹֽוב׃ \n"
     ]
    }
   ],
   "source": [
    "utils.caption(4, \"Test: paragraphs of the first verses\")\n",
    "\n",
    "\n",
    "def showParagraphs(verseNode):\n",
    "    clause_atoms = L.d(verseNode, otype=\"clause_atom\")\n",
    "    for ca in clause_atoms:\n",
    "        utils.caption(\n",
    "            0,\n",
    "            \"\\t\\t{:<3} {:>12} {}\".format(\n",
    "                F.instruction.v(ca), F.pargr.v(ca), T.text(L.d(ca, otype=\"word\"))\n",
    "            ),\n",
    "            continuation=True,\n",
    "        )\n",
    "\n",
    "\n",
    "for (i, verseNode) in enumerate(F.otype.s(\"verse\")[0:10]):\n",
    "    verseLabel = T.sectionFromNode(verseNode)\n",
    "    verseHeading = \"{} {}:{}\".format(*verseLabel) if i == 0 or True else verseLabel[2]\n",
    "    utils.caption(0, \"\\t{}\".format(verseHeading), continuation=True)\n",
    "    showParagraphs(verseNode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if SCRIPT:\n",
    "    stop(good=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
