{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"images/dans-small.png\"/>\n",
    "<img align=\"right\" src=\"images/tf-small.png\"/>\n",
    "<img align=\"right\" src=\"images/etcbc.png\"/>\n",
    "\n",
    "\n",
    "# Ketiv Qere\n",
    "\n",
    "This notebook can read ketiv-qere info in files issued by the ETCBC and transform them\n",
    "into new features.\n",
    "There will be new features at the word level.\n",
    "\n",
    "**NB** This conversion will not work for versions `4` and `4b`.\n",
    "\n",
    "## Discussion\n",
    "There are already `qere` and `qere_utf8` features in the MQL of the core data.\n",
    "However, there are several problems with those:\n",
    "\n",
    "* features that contain the after-word material, `qere_trailer` and `qere_trailer_utf8`\n",
    "  are missing;\n",
    "* if there is no qere, both features are filled with the empty string.\n",
    "  In this way we can make no distinction between a truly empty `qere` and the absence of a `qere`.\n",
    "\n",
    "That is why we reconstruct ketiv and qere from special files that are used by the ETCBC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import collections\n",
    "from tf.fabric import Fabric\n",
    "from tf.writing.transcription import Transcription\n",
    "import utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "See [operation](https://github.com/ETCBC/pipeline/blob/master/README.md#operation)\n",
    "for how to run this script in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if \"SCRIPT\" not in locals():\n",
    "    SCRIPT = False\n",
    "    FORCE = True\n",
    "    CORE_NAME = \"bhsa\"\n",
    "    VERSION = \"2021\"\n",
    "\n",
    "\n",
    "def stop(good=False):\n",
    "    if SCRIPT:\n",
    "        sys.exit(0 if good else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the context: source file and target directories\n",
    "\n",
    "The conversion is executed in an environment of directories, so that sources, temp files and\n",
    "results are in convenient places and do not have to be shifted around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repoBase = os.path.expanduser(\"~/github/etcbc\")\n",
    "thisRepo = \"{}/{}\".format(repoBase, CORE_NAME)\n",
    "\n",
    "thisSource = \"{}/source/{}\".format(thisRepo, VERSION)\n",
    "\n",
    "thisTemp = \"{}/_temp/{}\".format(thisRepo, VERSION)\n",
    "thisTempTf = \"{}/tf\".format(thisTemp)\n",
    "\n",
    "thisTf = \"{}/tf/{}\".format(thisRepo, VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testFeature = \"qere_trailer\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "Check whether this conversion is needed in the first place.\n",
    "Only when run as a script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if SCRIPT:\n",
    "    (good, work) = utils.mustRun(\n",
    "        None, \"{}/.tf/{}.tfx\".format(thisTf, testFeature), force=FORCE\n",
    "    )\n",
    "    if not good:\n",
    "        stop(good=False)\n",
    "    if not work:\n",
    "        stop(good=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Settings\n",
    "\n",
    "* a piece of metadata that will go into these features; the time will be added automatically\n",
    "* new text formats for the `otext` feature of TF, based on lexical features.\n",
    "  We select the version specific otext material,\n",
    "  falling back on a default if nothing appropriate has been specified in oText.\n",
    "\n",
    "We do not do this for the older versions `4` and `4b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|         16s New text formats\n",
      "|         16s fmt:text-orig-full             = \"{qere_utf8/g_word_utf8}{qere_trailer_utf8/trailer_utf8}\"\n",
      "|         16s fmt:text-orig-full-ketiv       = \"{g_word_utf8}{trailer_utf8}\"\n",
      "|         16s fmt:text-trans-full            = \"{qere/g_word}{qere_trailer/trailer}\"\n",
      "|         16s fmt:text-trans-full-ketiv      = \"{g_word}{trailer}\"\n"
     ]
    }
   ],
   "source": [
    "provenanceMetadata = dict(\n",
    "    dataset=\"BHSA\",\n",
    "    version=VERSION,\n",
    "    datasetName=\"Biblia Hebraica Stuttgartensia Amstelodamensis\",\n",
    "    author=\"Eep Talstra Centre for Bible and Computer\",\n",
    "    encoders=\"Constantijn Sikkel (QDF), and Dirk Roorda (TF)\",\n",
    "    website=\"https://shebanq.ancient-data.org\",\n",
    "    email=\"shebanq@ancient-data.org\",\n",
    ")\n",
    "\n",
    "oText = {\n",
    "    \"_temp\": \"\"\"\n",
    "@fmt:text-orig-full={qere_utf8/g_word_utf8}{qere_trailer_utf8/trailer_utf8}\n",
    "@fmt:text-orig-full-ketiv={g_word_utf8}{trailer_utf8}\n",
    "@fmt:text-trans-full={qere/g_word}{qere_trailer/trailer}\n",
    "@fmt:text-trans-full-ketiv={g_word}{trailer}\"\"\",\n",
    "    \"2021\": \"\"\"\n",
    "@fmt:text-orig-full={qere_utf8/g_word_utf8}{qere_trailer_utf8/trailer_utf8}\n",
    "@fmt:text-orig-full-ketiv={g_word_utf8}{trailer_utf8}\n",
    "@fmt:text-trans-full={qere/g_word}{qere_trailer/trailer}\n",
    "@fmt:text-trans-full-ketiv={g_word}{trailer}\"\"\",\n",
    "    \"2017\": \"\"\"\n",
    "@fmt:text-orig-full={qere_utf8/g_word_utf8}{qere_trailer_utf8/trailer_utf8}\n",
    "@fmt:text-orig-full-ketiv={g_word_utf8}{trailer_utf8}\n",
    "@fmt:text-trans-full={qere/g_word}{qere_trailer/trailer}\n",
    "@fmt:text-trans-full-ketiv={g_word}{trailer}\"\"\",\n",
    "    \"2016\": \"\"\"\n",
    "@fmt:text-orig-full={qere_utf8/g_word_utf8}{qere_trailer_utf8/trailer_utf8}\n",
    "@fmt:text-orig-full-ketiv={g_word_utf8}{trailer_utf8}\n",
    "@fmt:text-trans-full={qere/g_word}{qere_trailer/trailer}\n",
    "@fmt:text-trans-full-ketiv={g_word}{trailer}\"\"\",\n",
    "    \"c\": \"\"\"\n",
    "@fmt:text-orig-full={qere_utf8/g_word_utf8}{qere_trailer_utf8/trailer_utf8}\n",
    "@fmt:text-orig-full-ketiv={g_word_utf8}{trailer_utf8}\n",
    "@fmt:text-trans-full={qere/g_word}{qere_trailer/trailer}\n",
    "@fmt:text-trans-full-ketiv={g_word}{trailer}\"\"\",\n",
    "}\n",
    "\n",
    "thisOtext = oText.get(VERSION, \"\")\n",
    "\n",
    "if thisOtext == \"\":\n",
    "    utils.caption(0, \"No additional text formats provided\")\n",
    "    otextInfo = {}\n",
    "else:\n",
    "    utils.caption(0, \"New text formats\")\n",
    "    otextInfo = dict(\n",
    "        line[1:].split(\"=\", 1) for line in thisOtext.strip(\"\\n\").split(\"\\n\")\n",
    "    )\n",
    "    for x in sorted(otextInfo.items()):\n",
    "        utils.caption(0, '{:<30} = \"{}\"'.format(*x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".         18s Load the existing TF dataset                                                   .\n",
      "..............................................................................................\n",
      "This is Text-Fabric 8.5.13\n",
      "Api reference : https://annotation.github.io/text-fabric/tf/cheatsheet.html\n",
      "\n",
      "82 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.00s Dataset without structure sections in otext:no structure functions in the T-API\n",
      "  3.49s All features loaded/computed - for details use loadLog()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Computed',\n",
       "  'computed-data',\n",
       "  ('C Computed', 'Call AllComputeds', 'Cs ComputedString')),\n",
       " ('Features', 'edge-features', ('E Edge', 'Eall AllEdges', 'Es EdgeString')),\n",
       " ('Fabric', 'loading', ('TF',)),\n",
       " ('Locality', 'locality', ('L Locality',)),\n",
       " ('Nodes', 'navigating-nodes', ('N Nodes',)),\n",
       " ('Features',\n",
       "  'node-features',\n",
       "  ('F Feature', 'Fall AllFeatures', 'Fs FeatureString')),\n",
       " ('Search', 'search', ('S Search',)),\n",
       " ('Text', 'text', ('T Text',))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.caption(4, \"Load the existing TF dataset\")\n",
    "TF = Fabric(locations=thisTf, modules=[\"\"])\n",
    "api = TF.load(\"label g_word g_cons trailer_utf8\")\n",
    "api.makeAvailableIn(globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verse labels\n",
    "The ketiv-qere files deal with different verse labels.\n",
    "We make a mapping between verse labels and nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|         26s Mapping between verse labels and verse nodes\n",
      "|         26s 23213 verses\n"
     ]
    }
   ],
   "source": [
    "utils.caption(0, \"Mapping between verse labels and verse nodes\")\n",
    "nodeFromLabel = {}\n",
    "for vs in F.otype.s(\"verse\"):\n",
    "    lab = F.label.v(vs)\n",
    "    nodeFromLabel[lab] = vs\n",
    "utils.caption(0, \"{} verses\".format(len(nodeFromLabel)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the Ketiv-Qere file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".         30s Parsing Ketiv-Qere data                                                        .\n",
      "..............................................................................................\n",
      "|         30s \tRead 1892 ketiv-qere annotations\n"
     ]
    }
   ],
   "source": [
    "utils.caption(4, \"Parsing Ketiv-Qere data\")\n",
    "\n",
    "verseInfo = collections.defaultdict(lambda: [])\n",
    "notFound = set()\n",
    "missing = collections.defaultdict(lambda: [])\n",
    "missed = collections.defaultdict(lambda: [])\n",
    "\n",
    "error_limit = 10\n",
    "\n",
    "kqFile = \"{}/ketivqere.txt\".format(thisSource)\n",
    "kqHandle = open(kqFile)\n",
    "\n",
    "ln = 0\n",
    "can = 0\n",
    "cur_label = None\n",
    "for line in kqHandle:\n",
    "    ln += 1\n",
    "    can += 1\n",
    "    vlab = line[0:10]\n",
    "    fields = line.rstrip(\"\\n\")[10:].split()\n",
    "    (ketiv, qere) = fields[0:2]\n",
    "    (qtrim, qtrailer) = Transcription.suffix_and_finales(qere)\n",
    "    vnode = nodeFromLabel.get(vlab, None)\n",
    "    if vnode is None:\n",
    "        notFound.add(vlab)\n",
    "        continue\n",
    "    verseInfo[vnode].append((ketiv, qtrim, qtrailer))\n",
    "kqHandle.close()\n",
    "utils.caption(0, \"\\tRead {} ketiv-qere annotations\".format(ln))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|         38s \tParsed 1884 ketiv-qere annotations\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for vnode in verseInfo:\n",
    "    wlookup = collections.defaultdict(lambda: [])\n",
    "    wvisited = collections.defaultdict(lambda: -1)\n",
    "    wnodes = L.d(vnode, otype=\"word\")\n",
    "    for w in wnodes:\n",
    "        gw = F.g_word.v(w)\n",
    "        if \"*\" in gw:\n",
    "            gw = F.g_cons.v(w)\n",
    "            if gw == \"\":\n",
    "                gw = \".\"\n",
    "            if F.trailer_utf8.v(w) == \"\":\n",
    "                gw += \"-\"\n",
    "            wlookup[gw].append(w)\n",
    "    for (ketiv, qere, qtrailer) in verseInfo[vnode]:\n",
    "        wvisited[ketiv] += 1\n",
    "        windex = wvisited[ketiv]\n",
    "        ws = wlookup.get(ketiv, None)\n",
    "        if ws is None or windex > len(ws) - 1:\n",
    "            missing[vnode].append((windex, ketiv, qere))\n",
    "            continue\n",
    "        w = ws[windex]\n",
    "        qereU = Transcription.to_hebrew(qere)\n",
    "        qtrailerU = Transcription.to_hebrew(qtrailer)\n",
    "        data.append(\n",
    "            (\n",
    "                w,\n",
    "                ketiv,\n",
    "                qere,\n",
    "                qtrailer.replace(\"\\n\", \"\"),\n",
    "                qereU,\n",
    "                qtrailerU.replace(\"\\n\", \"\"),\n",
    "            )\n",
    "        )\n",
    "    for ketiv in wlookup:\n",
    "        if ketiv not in wvisited or len(wlookup[ketiv]) - 1 > wvisited[ketiv]:\n",
    "            missed[vnode].append(\n",
    "                (len(wlookup[ketiv]) - (wvisited.get(ketiv, -1) + 1), ketiv)\n",
    "            )\n",
    "utils.caption(0, \"\\tParsed {} ketiv-qere annotations\".format(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(297572, '<NWJ', '<:ANIJ.;J', '&', 'עֲנִיֵּי', '־')\n",
      "(297647, 'W-', 'W:', '', 'וְ', '')\n",
      "(297648, 'NCQH', 'NIC:Q:<@73H', ' ', 'נִשְׁקְעָ֖ה', ' ')\n",
      "(297938, 'M<LWTW', 'MA<:ALOWT@80JW', ' ', 'מַעֲלֹותָ֔יו', ' ')\n",
      "(370148, 'M>WM', 'MW.m04', ' ', 'מוּם֩', ' ')\n",
      "(370612, 'L-', 'L:', '', 'לְ', '')\n",
      "(370613, '<BDJK', '<AB:D@73k:', ' ', 'עַבְדָ֖ךְ', ' ')\n",
      "(370621, 'L-', 'L:', '', 'לְ', '')\n",
      "(370622, 'KFDJ>', 'KAF:D.@>;80J', ' ', 'כַשְׂדָּאֵ֔י', ' ')\n",
      "(370704, 'HZMNTWN', 'HIZ:D.:MIN:T.W.n03', ' ', 'הִזְדְּמִנְתּוּן֙', ' ')\n"
     ]
    }
   ],
   "source": [
    "if not SCRIPT:\n",
    "    print(\"\\n\".join(repr(d) for d in data[0:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|         52s \tAll verses entries found in index\n",
      "|         52s \tWARNING: Could not locate ketivs in the text: 8 verses\n",
      "|         52s \t\tNOT IN TEXT: RICHT16,25 KJ                   #0 K.:\n",
      "|         52s \t\tNOT IN TEXT: IISA 18,20 <L                   #0 <AL\n",
      "|         52s \t\tNOT IN TEXT:  JES 44,24 MJ                   #0 M;\n",
      "|         52s \t\tNOT IN TEXT:  IOB 38,12 H                    #0 HA\n",
      "|         52s \t\tNOT IN TEXT:  THR 01,06 MN                   #0 MI\n",
      "|         52s \t\tNOT IN TEXT:  THR 04,03 KJ                   #0 K.A\n",
      "|         52s \t\tNOT IN TEXT:  NEH 02,13 HM-                  #0 H;74m\n",
      "|         52s \t\tNOT IN TEXT:  ICHR27,12 BN-                  #0 B.;74n\n",
      "|         52s \tCould not lookup qeres in the data: 8 verses\n",
      "|         52s \t\tNOT IN DATA: RICHT16,25 KJ-                  #1\n",
      "|         52s \t\tNOT IN DATA: IISA 18,20 <L-                  #1\n",
      "|         52s \t\tNOT IN DATA:  JES 44,24 MJ-                  #1\n",
      "|         52s \t\tNOT IN DATA:  IOB 38,12 H-                   #1\n",
      "|         52s \t\tNOT IN DATA:  THR 01,06 MN-                  #1\n",
      "|         52s \t\tNOT IN DATA:  THR 04,03 KJ-                  #1\n",
      "|         52s \t\tNOT IN DATA:  NEH 02,13 HM                   #1\n",
      "|         52s \t\tNOT IN DATA:  ICHR27,12 BN                   #1\n"
     ]
    }
   ],
   "source": [
    "if notFound:\n",
    "    utils.caption(\n",
    "        0,\n",
    "        \"\\tWARNING: Could not find {} verses: {}\".format(\n",
    "            len(notFound), sorted(notFound)\n",
    "        ),\n",
    "    )\n",
    "else:\n",
    "    utils.caption(0, \"\\tAll verses entries found in index\")\n",
    "if missing:\n",
    "    utils.caption(\n",
    "        0,\n",
    "        \"\\tWARNING: Could not locate ketivs in the text: {} verses\".format(\n",
    "            len(missing)\n",
    "        ),\n",
    "    )\n",
    "    e = 0\n",
    "    for vnode in sorted(missing):\n",
    "        if e > error_limit:\n",
    "            break\n",
    "        vlab = F.label.v(vnode)\n",
    "        for (windex, ketiv, qere) in missing[vnode]:\n",
    "            e += 1\n",
    "            if e > error_limit:\n",
    "                break\n",
    "            utils.caption(\n",
    "                0,\n",
    "                \"\\t\\tNOT IN TEXT: {:<10} {:<20} #{} {}\".format(\n",
    "                    vlab, ketiv, windex, qere\n",
    "                ),\n",
    "            )\n",
    "else:\n",
    "    utils.caption(0, \"\\tAll ketivs found in the text\")\n",
    "if missed:\n",
    "    utils.caption(\n",
    "        0, \"\\tCould not lookup qeres in the data: {} verses\".format(len(missed))\n",
    "    )\n",
    "    e = 0\n",
    "    for vnode in sorted(missed):\n",
    "        if e > error_limit:\n",
    "            break\n",
    "        vlab = F.label.v(vnode)\n",
    "        for (windex, ketiv) in missed[vnode]:\n",
    "            e += 1\n",
    "            if e > error_limit:\n",
    "                break\n",
    "            utils.caption(\n",
    "                0, \"\\t\\tNOT IN DATA: {:<10} {:<20} #{}\".format(vlab, ketiv, windex)\n",
    "            )\n",
    "else:\n",
    "    utils.caption(0, \"\\tAll ketivs found in the data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare TF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|      3m 01s Prepare TF ketiv qere features\n"
     ]
    }
   ],
   "source": [
    "utils.caption(0, \"Prepare TF ketiv qere features\")\n",
    "\n",
    "nodeFeatures = {}\n",
    "\n",
    "newFeatures = \"\"\"\n",
    "    qere\n",
    "    qere_trailer\n",
    "    qere_utf8\n",
    "    qere_trailer_utf8\n",
    "\"\"\".strip().split()\n",
    "\n",
    "nodeFeatures = dict(\n",
    "    qere=dict(((x[0], x[2]) for x in data)),\n",
    "    qere_trailer=dict(((x[0], x[3]) for x in data)),\n",
    "    qere_utf8=dict(((x[0], x[4]) for x in data)),\n",
    "    qere_trailer_utf8=dict(((x[0], x[5]) for x in data)),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We update the `otext` feature with new/changed formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|      3m 05s Update the otext feature\n"
     ]
    }
   ],
   "source": [
    "utils.caption(0, \"Update the otext feature\")\n",
    "\n",
    "metaData = {\n",
    "    \"\": provenanceMetadata,\n",
    "}\n",
    "\n",
    "metaData[\"otext\"] = dict()\n",
    "metaData[\"otext\"].update(T.config)\n",
    "metaData[\"otext\"].update(otextInfo)\n",
    "\n",
    "for f in nodeFeatures:\n",
    "    metaData[f] = {}\n",
    "    metaData[f][\"valueType\"] = \"str\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "changedDataFeatures = set(nodeFeatures)\n",
    "changedFeatures = changedDataFeatures | {\"otext\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write new features\n",
    "Transform the collected information in feature-like datastructures, and write it all\n",
    "out to `.tf` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".      3m 09s write new/changed features to TF ...                                           .\n",
      "..............................................................................................\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.caption(4, \"write new/changed features to TF ...\")\n",
    "TF = Fabric(locations=thisTempTf, silent=True)\n",
    "TF.save(nodeFeatures=nodeFeatures, edgeFeatures={}, metaData=metaData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffs\n",
    "\n",
    "Check differences with previous versions.\n",
    "\n",
    "The new dataset has been created in a temporary directory,\n",
    "and has not yet been copied to its destination.\n",
    "\n",
    "Here is your opportunity to compare the newly created features with the older features.\n",
    "You expect some differences in some features.\n",
    "\n",
    "We check the differences between the previous version of the features and what has been generated.\n",
    "We list features that will be added and deleted and changed.\n",
    "For each changed feature we show the first line where the new feature differs from the old one.\n",
    "We ignore changes in the metadata, because the timestamp in the metadata will always change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".      3m 13s Check differences with previous version                                        .\n",
      "..............................................................................................\n",
      "|      3m 13s \t2 features to add\n",
      "|      3m 13s \t\tqere_trailer\n",
      "|      3m 13s \t\tqere_trailer_utf8\n",
      "|      3m 13s \tno features to delete\n",
      "|      3m 13s \t3 features in common\n",
      "|      3m 13s otext                     ... differences\n",
      "|      3m 13s \tline      5 OLD -->@dateWritten=2021-06-28T08:55:24Z<--\n",
      "|      3m 13s \tline      5 NEW -->@dateWritten=2021-06-28T08:59:31Z<--\n",
      "|      3m 13s \tline     12 OLD -->@fmt:text-orig-full={g_word_utf8}{traile ...<--\n",
      "|      3m 13s \tline     12 NEW -->@fmt:text-orig-full={qere_utf8/g_word_ut ...<--\n",
      "|      3m 13s \tline     13 OLD -->@fmt:text-orig-plain={g_cons_utf8}{trail ...<--\n",
      "|      3m 13s \tline     13 NEW -->@fmt:text-orig-full-ketiv={g_word_utf8}{ ...<--\n",
      "|      3m 13s \tline     14 OLD -->@fmt:text-trans-full={g_word}{trailer}<--\n",
      "|      3m 13s \tline     14 NEW -->@fmt:text-orig-plain={g_cons_utf8}{trail ...<--\n",
      "\n",
      "|      3m 13s qere                      ... differences after the metadata\n",
      "|      3m 13s \tline      2 OLD --><--\n",
      "|      3m 13s \tline      2 NEW -->3897\tHAJ:Y;74><--\n",
      "|      3m 13s \tline      3 OLD --><--\n",
      "|      3m 13s \tline      3 NEW -->4420\t>@H:@LO75W<--\n",
      "|      3m 13s \tline      4 OLD --><--\n",
      "|      3m 13s \tline      4 NEW -->5645\t>@H:@LO92W<--\n",
      "|      3m 13s \tline      5 OLD --><--\n",
      "|      3m 13s \tline      5 NEW -->5912\t>@95H:@LOW03<--\n",
      "\n",
      "|      3m 13s qere_utf8                 ... differences after the metadata\n",
      "|      3m 13s \tline      2 OLD --><--\n",
      "|      3m 13s \tline      2 NEW -->3897\tהַיְצֵ֣א<--\n",
      "|      3m 13s \tline      3 OLD --><--\n",
      "|      3m 13s \tline      3 NEW -->4420\tאָהֳלֹֽו<--\n",
      "|      3m 13s \tline      4 OLD --><--\n",
      "|      3m 13s \tline      4 NEW -->5645\tאָהֳלֹ֑ו<--\n",
      "|      3m 13s \tline      5 OLD --><--\n",
      "|      3m 13s \tline      5 NEW -->5912\tאָֽהֳלֹו֙<--\n",
      "\n",
      "|      3m 13s Done\n"
     ]
    }
   ],
   "source": [
    "utils.checkDiffs(thisTempTf, thisTf, only=changedFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deliver\n",
    "\n",
    "Copy the new TF dataset from the temporary location where it has been created to its final destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".      3m 17s Deliver features to /Users/dirk/github/etcbc/bhsa/tf/2021                      .\n",
      "..............................................................................................\n",
      "|      3m 17s \tqere_utf8\n",
      "|      3m 17s \tqere\n",
      "|      3m 17s \totext\n",
      "|      3m 17s \tqere_trailer_utf8\n",
      "|      3m 17s \tqere_trailer\n"
     ]
    }
   ],
   "source": [
    "utils.deliverFeatures(thisTempTf, thisTf, changedFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile TF\n",
    "\n",
    "We load the new features, use the new format, check some values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".      3m 20s Load and compile the new TF features                                           .\n",
      "..............................................................................................\n",
      "This is Text-Fabric 8.5.13\n",
      "Api reference : https://annotation.github.io/text-fabric/tf/cheatsheet.html\n",
      "\n",
      "84 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.00s Dataset without structure sections in otext:no structure functions in the T-API\n",
      "   |     0.01s T qere_trailer         from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.01s T qere                 from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.00s T qere_trailer_utf8    from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.01s T qere_utf8            from ~/github/etcbc/bhsa/tf/2021\n",
      "   |      |     0.66s C __levels__           from otype, oslots, otext\n",
      "   |      |       14s C __order__            from otype, oslots, __levels__\n",
      "   |      |     0.69s C __rank__             from otype, __order__\n",
      "   |      |       15s C __levUp__            from otype, oslots, __rank__\n",
      "   |      |     9.11s C __levDown__          from otype, __levUp__, __rank__\n",
      "   |      |     3.43s C __boundary__         from otype, oslots, __rank__\n",
      "   |      |     0.07s C __sections__         from otype, oslots, otext, __levUp__, __levels__, book, chapter, verse\n",
      "    44s All features loaded/computed - for details use loadLog()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Computed',\n",
       "  'computed-data',\n",
       "  ('C Computed', 'Call AllComputeds', 'Cs ComputedString')),\n",
       " ('Features', 'edge-features', ('E Edge', 'Eall AllEdges', 'Es EdgeString')),\n",
       " ('Fabric', 'loading', ('TF',)),\n",
       " ('Locality', 'locality', ('L Locality',)),\n",
       " ('Nodes', 'navigating-nodes', ('N Nodes',)),\n",
       " ('Features',\n",
       "  'node-features',\n",
       "  ('F Feature', 'Fall AllFeatures', 'Fs FeatureString')),\n",
       " ('Search', 'search', ('S Search',)),\n",
       " ('Text', 'text', ('T Text',))]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.caption(4, \"Load and compile the new TF features\")\n",
    "\n",
    "TF = Fabric(locations=thisTf, modules=[\"\"])\n",
    "api = TF.load(\n",
    "    \"g_word_utf8 g_word trailer_utf8 trailer {}\".format(\" \".join(changedDataFeatures))\n",
    ")\n",
    "api.makeAvailableIn(globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".      4m 08s Basic tests                                                                    .\n",
      "..............................................................................................\n",
      "|      4m 08s absence of qere               : NA NA WA J.I45C:T.AX:AW.75W. NA NA NA NA NA NA\n",
      "|      4m 08s presence of qere trailer      : NA NA NA &  \n",
      "..............................................................................................\n",
      ".      4m 08s Josua 15:52 in all formats                                                     .\n",
      "..............................................................................................\n",
      "|      4m 08s lex-orig-full                  אֲרַב וְ רוּמָה וְ אֶשְׁעָן \n",
      "|      4m 08s lex-orig-plain                 ארב ו רומה ו אשׁען \n",
      "|      4m 08s lex-trans-full                 >:ARAB W:- RW.M@H W:- >EC:<@N \n",
      "|      4m 08s lex-trans-plain                >RB W RWMH W >C<N \n",
      "|      4m 08s text-orig-full                 אֲרַ֥ב וְרוּמָ֖ה וְאֶשְׁעָֽן׃ \n",
      "|      4m 08s text-orig-full-ketiv           אֲרַ֥ב וְרוּמָ֖ה וְאֶשְׁעָֽן׃ \n",
      "|      4m 08s text-orig-plain                ארב ורומה ואשׁען׃ \n",
      "|      4m 08s text-trans-full                >:ARA71B W:-RW.M@73H W:->EC:<@75N00 \n",
      "|      4m 08s text-trans-full-ketiv          >:ARA71B W:-RW.M@73H W:->EC:<@75N00 \n",
      "|      4m 08s text-trans-plain               >RB WRWMH W>C<N00 \n"
     ]
    }
   ],
   "source": [
    "utils.caption(4, \"Basic tests\")\n",
    "\n",
    "\n",
    "def showKq(w):\n",
    "    hw = F.g_word_utf8.v(w)\n",
    "    tw = F.g_word.v(w)\n",
    "    ht = F.trailer_utf8.v(w)\n",
    "    tt = F.trailer.v(w)\n",
    "\n",
    "    qhw = F.qere_utf8.v(w)\n",
    "    qtw = F.qere.v(w)\n",
    "    qht = F.qere_trailer_utf8.v(w)\n",
    "    qtt = F.qere_trailer.v(w)\n",
    "\n",
    "    utils.caption(0, \"{:<20} {}\".format(\"hebrew\", hw + ht))\n",
    "    utils.caption(0, \"{:<20} {}\".format(\"hebrew qere\", qhw + qht))\n",
    "    utils.caption(0, \"{:<20} {}\".format(\"transcription\", tw + tt))\n",
    "    utils.caption(0, \"{:<20} {}\".format(\"transcription qere\", qtw + qtt))\n",
    "\n",
    "\n",
    "utils.caption(\n",
    "    0,\n",
    "    \"{:<30}: {}\".format(\n",
    "        \"absence of qere\",\n",
    "        \" \".join(\n",
    "            \"NA\" if F.qere.v(w) is None else F.qere.v(w) for w in (range(24700, 24710))\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "utils.caption(\n",
    "    0,\n",
    "    \"{:<30}: {}\".format(\n",
    "        \"presence of qere trailer\",\n",
    "        \" \".join(\n",
    "            \"NA\" if F.qere_trailer.v(w) is None else F.qere_trailer.v(w)\n",
    "            for w in (range(30190, 30195))\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "\n",
    "showNode = L.u(122073, otype=\"verse\")[0]\n",
    "showVerse = T.sectionFromNode(showNode)\n",
    "\n",
    "utils.caption(4, \"{} {}:{} in all formats\".format(*showVerse))\n",
    "for fmt in T.formats:\n",
    "    utils.caption(\n",
    "        0, \"{:<30} {}\".format(fmt, T.text(L.d(showNode, otype=\"word\"), fmt=fmt))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if SCRIPT:\n",
    "    stop(good=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
