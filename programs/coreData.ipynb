{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"images/dans-small.png\"/>\n",
    "<img align=\"right\" src=\"images/tf-small.png\"/>\n",
    "<img align=\"right\" src=\"images/etcbc.png\"/>\n",
    "\n",
    "\n",
    "![mql](images/emdros.png)\n",
    "\n",
    "# TF from MQL\n",
    "\n",
    "This notebook can read an\n",
    "[MQL](https://emdros.org/mql.html)\n",
    "dump of a version of the [BHSA](https://github.com/ETCBC/bhsa) Hebrew Text Database\n",
    "and transform it in a Text-Fabric\n",
    "[Text-Fabric](https://github.com/Dans-labs/text-fabric)\n",
    "resource.\n",
    "\n",
    "## Discussion\n",
    "\n",
    "The principled way of going about such a conversion is to import the MQL source into\n",
    "an [Emdros](https://emdros.org) database, and use it to retrieve objects and features from there.\n",
    "\n",
    "Because the syntax of an MQL file leaves some freedom, it is error prone to do a text-to-text conversion from\n",
    "MQL to something else.\n",
    "\n",
    "Yet this is what we do, the error-prone thing. We then avoid installing and configuring and managing Emdros, MYSQL/SQLite3.\n",
    "Aside the upfront work to get this going, the going after that would also be much slower.\n",
    "\n",
    "So here you are, a smallish script to do an awful lot of work, mostly correct, if careful used.\n",
    "\n",
    "# Caveat\n",
    "\n",
    "This notebook makes use of a new feature of text-fabric, first present in 2.3.12.\n",
    "Make sure to upgrade first.\n",
    "\n",
    "```sudo -H pip3 install --upgrade text-fabric\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from shutil import rmtree\n",
    "from tf.fabric import Fabric\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "See [operation](https://github.com/ETCBC/pipeline/blob/master/README.md#operation)\n",
    "for how to run this script in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"SCRIPT\" not in locals():\n",
    "    SCRIPT = False\n",
    "    FORCE = True\n",
    "    CORE_NAME = \"bhsa\"\n",
    "    VERSION = \"2021\"\n",
    "    RENAME = (\n",
    "        (\"g_suffix\", \"trailer\"),\n",
    "        (\"g_suffix_utf8\", \"trailer_utf8\"),\n",
    "    )\n",
    "\n",
    "\n",
    "def stop(good=False):\n",
    "    if SCRIPT:\n",
    "        sys.exit(0 if good else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the context: source file and target directories\n",
    "\n",
    "The conversion is executed in an environment of directories, so that sources, temp files and\n",
    "results are in convenient places and do not have to be shifted around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "repoBase = os.path.expanduser(\"~/github/etcbc\")\n",
    "thisRepo = \"{}/{}\".format(repoBase, CORE_NAME)\n",
    "\n",
    "thisSource = \"{}/source/{}\".format(thisRepo, VERSION)\n",
    "mqlzFile = \"{}/{}.mql.bz2\".format(thisSource, CORE_NAME)\n",
    "\n",
    "thisTemp = \"{}/_temp/{}\".format(thisRepo, VERSION)\n",
    "thisTempSource = \"{}/source\".format(thisTemp)\n",
    "mqlFile = \"{}/{}.mql\".format(thisTempSource, CORE_NAME)\n",
    "thisTempTf = \"{}/tf\".format(thisTemp)\n",
    "\n",
    "thisTf = \"{}/tf/{}\".format(thisRepo, VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "Check whether this conversion is needed in the first place.\n",
    "Only when run as a script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SCRIPT:\n",
    "    testFile = \"{}/.tf/otype.tfx\".format(thisTf)\n",
    "    (good, work) = utils.mustRun(\n",
    "        mqlzFile, \"{}/.tf/otype.tfx\".format(thisTf), force=FORCE\n",
    "    )\n",
    "    if not good:\n",
    "        stop(good=False)\n",
    "    if not work:\n",
    "        stop(good=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Settings\n",
    "\n",
    "We add some custom information here.\n",
    "\n",
    "* the MQL object type that corresponds to the Text-Fabric slot type, typically `word`;\n",
    "* a piece of metadata that will go into every feature; the time will be added automatically\n",
    "* suitable text formats for the `otext` feature of TF.\n",
    "\n",
    "The oText feature is very sensitive to what is available in the source MQL.\n",
    "It needs to be configured here.\n",
    "We save the configs we need per source and version.\n",
    "And we define a stripped down default version to start with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "slotType = \"word\"\n",
    "\n",
    "featureMetaData = dict(\n",
    "    dataset=\"BHSA\",\n",
    "    version=VERSION,\n",
    "    datasetName=\"Biblia Hebraica Stuttgartensia Amstelodamensis\",\n",
    "    author=\"Eep Talstra Centre for Bible and Computer\",\n",
    "    encoders=\"Constantijn Sikkel (QDF), Ulrik Petersen (MQL) and Dirk Roorda (TF)\",\n",
    "    website=\"https://shebanq.ancient-data.org\",\n",
    "    email=\"shebanq@ancient-data.org\",\n",
    ")\n",
    "\n",
    "oText = {\n",
    "    \"\": {\n",
    "        \"\": \"\"\"\n",
    "@sectionFeatures=book,chapter,verse\n",
    "@sectionTypes=book,chapter,verse\n",
    "@fmt:text-orig-full={g_word_utf8}{g_suffix_utf8}\n",
    "\"\"\",\n",
    "    },\n",
    "    \"_temp\": \"\"\"\n",
    "@fmt:lex-orig-full={g_lex_utf8} \n",
    "@fmt:lex-orig-plain={lex_utf8} \n",
    "@fmt:lex-trans-full={g_lex} \n",
    "@fmt:lex-trans-plain={lex} \n",
    "@fmt:text-orig-full={g_word_utf8}{trailer_utf8}\n",
    "@fmt:text-orig-plain={g_cons_utf8}{trailer_utf8}\n",
    "@fmt:text-trans-full={g_word}{trailer}\n",
    "@fmt:text-trans-plain={g_cons}{trailer}\n",
    "@sectionFeatures=book,chapter,verse\n",
    "@sectionTypes=book,chapter,verse\n",
    "\"\"\",  # noqa W291\n",
    "    \"2021\": \"\"\"\n",
    "@fmt:lex-orig-full={g_lex_utf8} \n",
    "@fmt:lex-orig-plain={lex_utf8} \n",
    "@fmt:lex-trans-full={g_lex} \n",
    "@fmt:lex-trans-plain={lex} \n",
    "@fmt:text-orig-full={g_word_utf8}{trailer_utf8}\n",
    "@fmt:text-orig-plain={g_cons_utf8}{trailer_utf8}\n",
    "@fmt:text-trans-full={g_word}{trailer}\n",
    "@fmt:text-trans-plain={g_cons}{trailer}\n",
    "@sectionFeatures=book,chapter,verse\n",
    "@sectionTypes=book,chapter,verse\n",
    "\"\"\",  # noqa W291\n",
    "    \"2017\": \"\"\"\n",
    "@fmt:lex-orig-full={g_lex_utf8} \n",
    "@fmt:lex-orig-plain={lex_utf8} \n",
    "@fmt:lex-trans-full={g_lex} \n",
    "@fmt:lex-trans-plain={lex} \n",
    "@fmt:text-orig-full={g_word_utf8}{trailer_utf8}\n",
    "@fmt:text-orig-plain={g_cons_utf8}{trailer_utf8}\n",
    "@fmt:text-trans-full={g_word}{trailer}\n",
    "@fmt:text-trans-plain={g_cons}{trailer}\n",
    "@sectionFeatures=book,chapter,verse\n",
    "@sectionTypes=book,chapter,verse\n",
    "\"\"\",  # noqa W291\n",
    "    \"2016\": \"\"\"\n",
    "@fmt:lex-orig-full={g_lex_utf8} \n",
    "@fmt:lex-orig-plain={lex_utf8} \n",
    "@fmt:lex-trans-full={g_lex} \n",
    "@fmt:lex-trans-plain={lex} \n",
    "@fmt:text-orig-full={g_word_utf8}{trailer_utf8}\n",
    "@fmt:text-orig-plain={g_cons_utf8}{trailer_utf8}\n",
    "@fmt:text-trans-full={g_word}{trailer}\n",
    "@fmt:text-trans-plain={g_cons}{trailer}\n",
    "@sectionFeatures=book,chapter,verse\n",
    "@sectionTypes=book,chapter,verse\n",
    "\"\"\",  # noqa W291\n",
    "    \"4b\": \"\"\"\n",
    "@fmt:lex-orig-full={g_lex_utf8} \n",
    "@fmt:lex-orig-plain={lex_utf8} \n",
    "@fmt:lex-trans-full={g_lex} \n",
    "@fmt:lex-trans-plain={lex} \n",
    "@fmt:text-orig-full={g_word_utf8}{trailer_utf8}\n",
    "@fmt:text-orig-full-ketiv={g_word_utf8}{trailer_utf8}\n",
    "@fmt:text-orig-plain={g_cons_utf8}{trailer_utf8}\n",
    "@fmt:text-trans-full={g_word} \n",
    "@fmt:text-trans-full-ketiv={g_word} \n",
    "@fmt:text-trans-plain={g_cons} \n",
    "@sectionFeatures=book,chapter,verse\n",
    "@sectionTypes=book,chapter,verse\n",
    "\"\"\",  # noqa W291\n",
    "    \"4\": \"\"\"\n",
    "@fmt:lex-orig-full={g_lex_utf8} \n",
    "@fmt:lex-orig-plain={lex_utf8} \n",
    "@fmt:lex-trans-full={g_lex} \n",
    "@fmt:lex-trans-plain={lex} \n",
    "@fmt:text-orig-full={g_word_utf8}{trailer_utf8}\n",
    "@fmt:text-orig-full-ketiv={g_word_utf8}{trailer_utf8}\n",
    "@fmt:text-orig-plain={g_cons_utf8}{trailer_utf8}\n",
    "@fmt:text-trans-full={g_word} \n",
    "@fmt:text-trans-full-ketiv={g_word} \n",
    "@fmt:text-trans-plain={g_cons} \n",
    "@sectionFeatures=book,chapter,verse\n",
    "@sectionTypes=book,chapter,verse\n",
    "\"\"\",  # noqa W291\n",
    "    \"3\": \"\"\"\n",
    "@fmt:lex-orig-full={graphical_lexeme_utf8} \n",
    "@fmt:lex-orig-plain={lexeme_utf8} \n",
    "@fmt:lex-trans-full={graphical_lexeme} \n",
    "@fmt:lex-trans-plain={lexeme} \n",
    "@fmt:text-orig-full={text}{suffix}\n",
    "@fmt:text-orig-plain={surface_consonants_utf8}{suffix}\n",
    "@fmt:text-trans-full={graphical_word} \n",
    "@fmt:text-trans-plain={surface_consonants} \n",
    "@sectionFeatures=book,chapter,verse\n",
    "@sectionTypes=book,chapter,verse\n",
    "\"\"\",  # noqa W291\n",
    "    \"c\": \"\"\"\n",
    "@fmt:lex-orig-full={g_lex_utf8} \n",
    "@fmt:lex-orig-plain={lex_utf8} \n",
    "@fmt:lex-trans-full={g_lex} \n",
    "@fmt:lex-trans-plain={lex} \n",
    "@fmt:text-orig-full={g_word_utf8}{trailer_utf8}\n",
    "@fmt:text-orig-plain={g_cons_utf8}{trailer_utf8}\n",
    "@fmt:text-trans-full={g_word}{trailer}\n",
    "@fmt:text-trans-plain={g_cons}{trailer}\n",
    "@sectionFeatures=book,chapter,verse\n",
    "@sectionTypes=book,chapter,verse\n",
    "\"\"\",  # noqa W291\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function selects the proper otext material, falling back on a default if nothing\n",
    "appropriate has been specified in `oText`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|       0.00s INFO: otext feature information found\n",
      "|       0.00s \tfmt:lex-orig-full    = \"{g_lex_utf8} \"\n",
      "|       0.00s \tfmt:lex-orig-plain   = \"{lex_utf8} \"\n",
      "|       0.00s \tfmt:lex-trans-full   = \"{g_lex} \"\n",
      "|       0.00s \tfmt:lex-trans-plain  = \"{lex} \"\n",
      "|       0.00s \tfmt:text-orig-full   = \"{g_word_utf8}{trailer_utf8}\"\n",
      "|       0.00s \tfmt:text-orig-plain  = \"{g_cons_utf8}{trailer_utf8}\"\n",
      "|       0.00s \tfmt:text-trans-full  = \"{g_word}{trailer}\"\n",
      "|       0.00s \tfmt:text-trans-plain = \"{g_cons}{trailer}\"\n",
      "|       0.00s \tsectionFeatures      = \"book,chapter,verse\"\n",
      "|       0.00s \tsectionTypes         = \"book,chapter,verse\"\n"
     ]
    }
   ],
   "source": [
    "thisOtext = oText.get(VERSION, oText[\"\"])\n",
    "\n",
    "if thisOtext is oText[\"\"]:\n",
    "    utils.caption(\n",
    "        0, \"WARNING: no otext feature info provided, using a meager default value\"\n",
    "    )\n",
    "    otextInfo = {}\n",
    "else:\n",
    "    utils.caption(0, \"INFO: otext feature information found\")\n",
    "    otextInfo = dict(\n",
    "        line[1:].split(\"=\", 1) for line in thisOtext.strip(\"\\n\").split(\"\\n\")\n",
    "    )\n",
    "    for x in sorted(otextInfo.items()):\n",
    "        utils.caption(0, '\\t{:<20} = \"{}\"'.format(*x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "The program has several stages:\n",
    "\n",
    "1. **prepare** the source (utils.bunzip if needed)\n",
    "1. **convert** convert the MQL file into a text-fabric dataset\n",
    "1. **differences** (informational)\n",
    "1. **deliver** the TF data at its destination directory\n",
    "1. **compile** all TF features to binary format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare\n",
    "\n",
    "Check the source, utils.bunzip it if needed, empty the result directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|       2.01s bunzipping /Users/dirk/github/etcbc/bhsa/source/2021/bhsa.mql.bz2 ...\n",
      "|       2.01s \tNOTE: Using existing unzipped file which is newer than bzipped one\n",
      "|       2.01s Done\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(thisTempSource):\n",
    "    os.makedirs(thisTempSource)\n",
    "\n",
    "utils.caption(0, \"bunzipping {} ...\".format(mqlzFile))\n",
    "utils.bunzip(mqlzFile, mqlFile)\n",
    "utils.caption(0, \"Done\")\n",
    "\n",
    "if os.path.exists(thisTempTf):\n",
    "    rmtree(thisTempTf)\n",
    "os.makedirs(thisTempTf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MQL to Text-Fabric\n",
    "Transform the collected information in feature-like data-structures, and write it all\n",
    "out to `.tf` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF = Fabric(locations=thisTempTf, silent=True)\n",
    "TF.importMQL(mqlFile, slotType=slotType, otext=otextInfo, meta=featureMetaData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename features\n",
    "We rename the features mentioned in the RENAME dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".      3m 41s Renaming 2 features in /Users/dirk/github/etcbc/bhsa/_temp/2021/tf             .\n",
      "..............................................................................................\n",
      "|      3m 41s \trenamed g_suffix to trailer\n",
      "|      3m 41s \trenamed g_suffix_utf8 to trailer_utf8\n"
     ]
    }
   ],
   "source": [
    "if RENAME is None:\n",
    "    utils.caption(4, \"Rename features: nothing to do\")\n",
    "else:\n",
    "    utils.caption(4, \"Renaming {} features in {}\".format(len(RENAME), thisTempTf))\n",
    "    for (srcFeature, dstFeature) in RENAME:\n",
    "        srcPath = \"{}/{}.tf\".format(thisTempTf, srcFeature)\n",
    "        dstPath = \"{}/{}.tf\".format(thisTempTf, dstFeature)\n",
    "        if os.path.exists(srcPath):\n",
    "            os.rename(srcPath, dstPath)\n",
    "            utils.caption(0, \"\\trenamed {} to {}\".format(srcFeature, dstFeature))\n",
    "        else:\n",
    "            utils.caption(0, \"\\tsource feature {} does not exist.\".format(srcFeature))\n",
    "            utils.caption(\n",
    "                0, \"\\tdestination feature {} will not be created.\".format(dstFeature)\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffs\n",
    "\n",
    "Check differences with previous versions.\n",
    "\n",
    "The new dataset has been created in a temporary directory,\n",
    "and has not yet been copied to its destination.\n",
    "\n",
    "Here is your opportunity to compare the newly created features with the older features.\n",
    "You expect some differences in some features.\n",
    "\n",
    "We check the differences between the previous version of the features and what has been generated.\n",
    "We list features that will be added and deleted and changed.\n",
    "For each changed feature we show the first line where the new feature differs from the old one.\n",
    "We ignore changes in the metadata, because the timestamp in the metadata will always change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".      3m 43s Check differences with previous version                                        .\n",
      "..............................................................................................\n",
      "|      3m 43s \t75 features to add\n",
      "|      3m 43s \t\tbook\n",
      "|      3m 43s \t\tchapter\n",
      "|      3m 43s \t\tcode\n",
      "|      3m 43s \t\tdet\n",
      "|      3m 43s \t\tdist\n",
      "|      3m 43s \t\tdist_unit\n",
      "|      3m 43s \t\tdistributional_parent\n",
      "|      3m 43s \t\tdomain\n",
      "|      3m 43s \t\tfunction\n",
      "|      3m 43s \t\tfunctional_parent\n",
      "|      3m 43s \t\tg_cons\n",
      "|      3m 43s \t\tg_cons_utf8\n",
      "|      3m 43s \t\tg_lex\n",
      "|      3m 43s \t\tg_lex_utf8\n",
      "|      3m 43s \t\tg_nme\n",
      "|      3m 43s \t\tg_nme_utf8\n",
      "|      3m 43s \t\tg_pfm\n",
      "|      3m 43s \t\tg_pfm_utf8\n",
      "|      3m 43s \t\tg_prs\n",
      "|      3m 43s \t\tg_prs_utf8\n",
      "|      3m 43s \t\tg_uvf\n",
      "|      3m 43s \t\tg_uvf_utf8\n",
      "|      3m 43s \t\tg_vbe\n",
      "|      3m 43s \t\tg_vbe_utf8\n",
      "|      3m 43s \t\tg_vbs\n",
      "|      3m 43s \t\tg_vbs_utf8\n",
      "|      3m 43s \t\tg_voc_lex\n",
      "|      3m 43s \t\tg_voc_lex_utf8\n",
      "|      3m 43s \t\tg_word\n",
      "|      3m 43s \t\tg_word_utf8\n",
      "|      3m 43s \t\tgn\n",
      "|      3m 43s \t\tis_root\n",
      "|      3m 43s \t\tkind\n",
      "|      3m 43s \t\tkq_hybrid\n",
      "|      3m 43s \t\tkq_hybrid_utf8\n",
      "|      3m 43s \t\tlabel\n",
      "|      3m 43s \t\tlanguage\n",
      "|      3m 43s \t\tlex\n",
      "|      3m 43s \t\tlex_utf8\n",
      "|      3m 43s \t\tlexeme_count\n",
      "|      3m 43s \t\tls\n",
      "|      3m 43s \t\tmother\n",
      "|      3m 43s \t\tmother_object_type\n",
      "|      3m 43s \t\tnme\n",
      "|      3m 43s \t\tnu\n",
      "|      3m 43s \t\tnumber\n",
      "|      3m 43s \t\toslots\n",
      "|      3m 43s \t\totext\n",
      "|      3m 43s \t\totype\n",
      "|      3m 43s \t\tpdp\n",
      "|      3m 43s \t\tpfm\n",
      "|      3m 43s \t\tprs\n",
      "|      3m 43s \t\tprs_gn\n",
      "|      3m 43s \t\tprs_nu\n",
      "|      3m 43s \t\tprs_ps\n",
      "|      3m 43s \t\tps\n",
      "|      3m 43s \t\tqere\n",
      "|      3m 43s \t\tqere_utf8\n",
      "|      3m 43s \t\trela\n",
      "|      3m 43s \t\tsp\n",
      "|      3m 43s \t\tst\n",
      "|      3m 43s \t\tsuffix_gender\n",
      "|      3m 43s \t\tsuffix_number\n",
      "|      3m 43s \t\tsuffix_person\n",
      "|      3m 43s \t\ttab\n",
      "|      3m 43s \t\ttrailer\n",
      "|      3m 43s \t\ttrailer_utf8\n",
      "|      3m 43s \t\ttxt\n",
      "|      3m 43s \t\ttyp\n",
      "|      3m 43s \t\tuvf\n",
      "|      3m 43s \t\tvbe\n",
      "|      3m 43s \t\tvbs\n",
      "|      3m 43s \t\tverse\n",
      "|      3m 43s \t\tvs\n",
      "|      3m 43s \t\tvt\n",
      "|      3m 43s \tno features to delete\n",
      "|      3m 43s \t0 features in common\n",
      "|      3m 43s Done\n"
     ]
    }
   ],
   "source": [
    "utils.checkDiffs(thisTempTf, thisTf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deliver\n",
    "\n",
    "Copy the new TF dataset from the temporary location where it has been created to its final destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".      3m 46s Deliver data set to /Users/dirk/github/etcbc/bhsa/tf/2021                      .\n",
      "..............................................................................................\n"
     ]
    }
   ],
   "source": [
    "utils.deliverDataset(thisTempTf, thisTf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile TF\n",
    "\n",
    "Just to see whether everything loads and the pre-computing of extra information works out.\n",
    "Moreover, if you want to work with these features, then the pre-computing has already been done, and everything is quicker in subsequent runs.\n",
    "\n",
    "We issue load statement to trigger the pre-computing of extra data.\n",
    "Note that all features specified text formats in the `otext` config feature,\n",
    "will be loaded, as well as the features for sections.\n",
    "\n",
    "At that point we have access to the full list of features.\n",
    "We grab them and are going to load them all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".      3m 53s Load and compile standard TF features                                          .\n",
      "..............................................................................................\n",
      "This is Text-Fabric 8.5.13\n",
      "Api reference : https://annotation.github.io/text-fabric/tf/cheatsheet.html\n",
      "\n",
      "75 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.50s T otype                from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     6.76s T oslots               from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.00s Dataset without structure sections in otext:no structure functions in the T-API\n",
      "   |     0.84s T lex                  from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.99s T g_word_utf8          from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.90s T g_cons_utf8          from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.90s T g_lex_utf8           from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.68s T trailer_utf8         from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.03s T chapter              from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.93s T g_word               from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.84s T g_cons               from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.85s T g_lex                from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.88s T lex_utf8             from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.65s T trailer              from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.04s T verse                from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.05s T book                 from ~/github/etcbc/bhsa/tf/2021\n",
      "   |      |     0.64s C __levels__           from otype, oslots, otext\n",
      "   |      |       12s C __order__            from otype, oslots, __levels__\n",
      "   |      |     0.63s C __rank__             from otype, __order__\n",
      "   |      |       12s C __levUp__            from otype, oslots, __rank__\n",
      "   |      |     8.14s C __levDown__          from otype, __levUp__, __rank__\n",
      "   |      |     3.33s C __boundary__         from otype, oslots, __rank__\n",
      "   |      |     0.07s C __sections__         from otype, oslots, otext, __levUp__, __levels__, book, chapter, verse\n",
      "    53s All features loaded/computed - for details use loadLog()\n",
      "..............................................................................................\n",
      ".      4m 46s Load and compile all other TF features                                         .\n",
      "..............................................................................................\n",
      "   |     0.00s Feature overview: 70 for nodes; 4 for edges; 1 configs; 8 computed\n",
      "  0.00s loading features ...\n",
      "   |     0.00s Dataset without structure sections in otext:no structure functions in the T-API\n",
      "   |     0.13s T code                 from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.96s T det                  from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     1.01s T dist                 from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     1.16s T dist_unit            from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     3.50s T distributional_parent from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.16s T domain               from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.48s T function             from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     4.83s T functional_parent    from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.63s T g_nme                from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.62s T g_nme_utf8           from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.46s T g_pfm                from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.46s T g_pfm_utf8           from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.47s T g_prs                from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.47s T g_prs_utf8           from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.43s T g_uvf                from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.42s T g_uvf_utf8           from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.50s T g_vbe                from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.45s T g_vbe_utf8           from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.44s T g_vbs                from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.43s T g_vbs_utf8           from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.84s T g_voc_lex            from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.91s T g_voc_lex_utf8       from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.79s T gn                   from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.17s T is_root              from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.16s T kind                 from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.42s T kq_hybrid            from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.43s T kq_hybrid_utf8       from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.13s T label                from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.79s T language             from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.58s T lexeme_count         from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.79s T ls                   from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.95s T mother               from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.42s T mother_object_type   from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.71s T nme                  from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.78s T nu                   from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     1.63s T number               from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.83s T pdp                  from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.80s T pfm                  from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.82s T prs                  from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.78s T prs_gn               from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.79s T prs_nu               from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.80s T prs_ps               from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.80s T ps                   from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.42s T qere                 from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.41s T qere_utf8            from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     1.37s T rela                 from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.81s T sp                   from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.77s T st                   from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.77s T suffix_gender        from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.79s T suffix_number        from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.80s T suffix_person        from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.12s T tab                  from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.16s T txt                  from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     1.33s T typ                  from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.80s T uvf                  from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.75s T vbe                  from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.82s T vbs                  from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.80s T vs                   from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.81s T vt                   from ~/github/etcbc/bhsa/tf/2021\n",
      "    47s All features loaded/computed - for details use loadLog()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Computed',\n",
       "  'computed-data',\n",
       "  ('C Computed', 'Call AllComputeds', 'Cs ComputedString')),\n",
       " ('Features', 'edge-features', ('E Edge', 'Eall AllEdges', 'Es EdgeString')),\n",
       " ('Fabric', 'loading', ('TF',)),\n",
       " ('Locality', 'locality', ('L Locality',)),\n",
       " ('Nodes', 'navigating-nodes', ('N Nodes',)),\n",
       " ('Features',\n",
       "  'node-features',\n",
       "  ('F Feature', 'Fall AllFeatures', 'Fs FeatureString')),\n",
       " ('Search', 'search', ('S Search',)),\n",
       " ('Text', 'text', ('T Text',))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.caption(4, \"Load and compile standard TF features\")\n",
    "TF = Fabric(locations=thisTf, modules=[\"\"])\n",
    "api = TF.load(\"\")\n",
    "\n",
    "utils.caption(4, \"Load and compile all other TF features\")\n",
    "allFeatures = TF.explore(silent=False, show=True)\n",
    "loadableFeatures = allFeatures[\"nodes\"] + allFeatures[\"edges\"]\n",
    "api = TF.load(loadableFeatures)\n",
    "api.makeAvailableIn(globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".      5m 37s Basic test                                                                     .\n",
      "..............................................................................................\n",
      "..............................................................................................\n",
      ".      5m 37s First verse in all formats                                                     .\n",
      "..............................................................................................\n",
      "lex-orig-full\n",
      "\tבְּ רֵאשִׁית בָּרָא אֱלֹה אֵת הַ שָּׁמַי וְ אֵת הָ אָרֶץ \n",
      "lex-orig-plain\n",
      "\tב ראשׁית֜ ברא אלהים֜ את ה שׁמים֜ ו את ה ארץ֜ \n",
      "lex-trans-full\n",
      "\tB.:- R;>CIJT B.@R@> >:ELOH >;T HA- C.@MAJ W:- >;T H@- >@REY \n",
      "lex-trans-plain\n",
      "\tB R>CJT/ BR>[ >LHJM/ >T H CMJM/ W >T H >RY/ \n",
      "text-orig-full\n",
      "\tבְּרֵאשִׁ֖ית בָּרָ֣א אֱלֹהִ֑ים אֵ֥ת הַשָּׁמַ֖יִם וְאֵ֥ת הָאָֽרֶץ׃ \n",
      "text-orig-plain\n",
      "\tבראשׁית ברא אלהים את השׁמים ואת הארץ׃ \n",
      "text-trans-full\n",
      "\tB.:-R;>CI73JT B.@R@74> >:ELOHI92JM >;71T HA-C.@MA73JIM W:->;71T H@->@75REY00 \n",
      "text-trans-plain\n",
      "\tBR>CJT BR> >LHJM >T HCMJM W>T H>RY00 \n"
     ]
    }
   ],
   "source": [
    "utils.caption(4, \"Basic test\")\n",
    "utils.caption(4, \"First verse in all formats\")\n",
    "for fmt in T.formats:\n",
    "    utils.caption(0, \"{}\".format(fmt), continuation=True)\n",
    "    utils.caption(0, \"\\t{}\".format(T.text(range(1, 12), fmt=fmt)), continuation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if SCRIPT:\n",
    "    stop(good=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    15s Node feature \"subphrase_type\" not loaded\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'freqList'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-ecb467d6013a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'subphrase_type'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'` `'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mFs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreqList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'`'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'freqList'"
     ]
    }
   ],
   "source": [
    "f = \"subphrase_type\"\n",
    "print(\"`\" + \"` `\".join(sorted(str(x[0]) for x in Fs(f).freqList())) + \"`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
